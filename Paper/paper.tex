\documentclass[twocolumn]{IEEEtran}
\usepackage{epsfig}
%-----------------------

\begin{document}


\title{Incremental Improvements of Software Implemented RSA on multiple processors}


\author{Christian D. Tuen \& Kine Johnsrud
\thanks{Authors are with the
Department of Computer Science,
University of California, Santa Barbara, CA 93106.
E-mail: \texttt{\{christiandt,kinej\}@umail.ucsb.edu}}
}

%\markboth{IEEE Transactions On Computers, Vol. 51, No. 5, May 2002}
%{Me and You}

\maketitle

\begin{abstract}
RSA is one of the first practicable public-key cryptosystems, and is widely used for secure data transmission. In this paper we present three different algorithms for calculating the modular exponentiation, and measure their impact on overall speed performance of RSA on different types of processors.
\end{abstract}

\section{Introduction}
RSA is an asymmetric key scheme where the encryption key is public, and the decryption key is kept private. The security of RSA is based on the difficulty of factoring the product of two large prime numbers. RSA uses the same computation for both encryption and decryption.

\bigskip

\centerline{$C = M^e \pmod{n}$}
\centerline{$M = C^d \pmod{n}$}

\bigskip

where n = pq, and p and q are two large primes. For more information about the mathematics of RSA, refer to Rivest et al.~\cite{rsa}. RSA can be used to encrypt and exchange private messages, as long as the message is smaller than the size of the key. RSA is more often used as a way to sign and verify digital documents. 

In this paper, we will discuss three ways to implement RSA. We will implement three fast and viable methods, called the binary method, recoding binary method, and montgomery exponentiation method. We have chosen to run the algorithms on three different processor architectures, to show the importance of efficiency when the hardware speeds are lower. The three processors are an Intel i7 in a Macbook Air, the processor of the UDOO development board, and the processor of the arduino-part of the UDOO development board.

\section{Description}
In this section we will discuss the various algorithms we chose to implement, and their main improvement features. We have implemented the binary method, recoding binary method, and montgomery exponentiation.

\subsection*{Binary Method}
In the binary method, we represent the exponents $e$ and $d$ in binary, and scan them from left to right. We call the number of bits $k$. For each bit, we perform a squaring, and if the bit is a 1, we also perform a subsequent multiplication. This gives an order of magnitude fewer operations than the naive method, as the maximum number of multiplications is $2(k-1)$.

\subsection*{Recoding Binary Method}
If the binary representation of the exponent contains a lot of 1’s, the standard binary methods performance will be worst-case. The recoding method is used to collapse a block of 1’s to obtain a sparse representation of the exponent. We need to introduce the $\bar{1}$, to represent -1. An example: $011110 \rightarrow 1000\bar{1}0$. A tradeoff is that this algorithm requires the inverse of $M$ modulo $n$, which is a costly operation and makes these kind of techniques less valuable for RSA.

\subsection*{Montgomery Exponentiation Method}
Last but not least, we implemented the Montgomery Exponentiation method, that also uses the Montgomery Product algorithm. This algorithm is best explained by Koc et al.~\cite{koc}, but the idea is that this is a reduction algorithm that performs multiplication faster than the conventional way. This algorithm is proven faster than the ones we have previously discussed, but the amount of overhead (pre-calculations) needed makes the effect of the efficient core algorithm hard to detect on our small-numbered set of values.

\begin{table*}[!htb] 
\textbf{Table 1:} Time in seconds of 1000 encryptions and decryptions in RSA \\[1em]
    \centering
    \begin{tabular}{|l|l|l|l|}
    \hline
    {\bf Processor}                                 & {\bf Binary}   & {\bf Recoding Binary} & {\bf Montgomery} \\ \hline
    Intel i7 Dual Core 2.0GHz                 & 0.000592 & 0.001119        & 0.002410   \\ \hline
    Freescale i.MX 6 Cortex-A9 Dual Core 1GHz & 0.005600 & 0.008667        & N/A       \\ \hline
    Atmel SAM3X8E ARM Cortex-M3 CPU           & 0.012333 & 0.036667        & N/A       \\ \hline
    \end{tabular}
\end{table*}

\section{Setup}
We decided early on in the project not to use any big-number libraries. This decision was made both because we did not want to be bound to the limitations of the library, and did not want the results to be influenced by the library's implementation. By not using any libraries to handle big numbers, we are restricted to the maximum number size allowed by the processor. As we are comparing the performance across three different processors, we need to use the same values across all, and are thus restricted by the processor with the lowest maximum number size. 

All code is implemented using the C programming language.  We wanted to use a "lower-level" programming language than for example Python, so that it would not influence the performance of the implemented algorithms in any major way. In addition, the microcontroller used during testing is programmed using C, and thus only slight modifications of the program code needed to be made for it to on all three processors.

As earlier stated, performance-testing is performed using three different processors. One high-end Intel processor, a middle-performing ARM processor, and a low-end microcontroller. Testing of the Intel processor is done on a 2013 Apple MacBook Air using the OSX operating system. This is a dual-core 2.0GHz, 64 bit processor, and represents the high-end in our testing. The middle-end processor is a Freescale i.MX 6 Cortex-A9 Dual Core 1GHz and is tested using the Ubuntu Linux distribution on a UDOO computer. Finally, the low-end processor is a Atmel SAM3X8E ARM Cortex-M3 CPU also on the UDOO board, but run separately from the rest of the board.

\section{Results}
This section shows the numerical results after running the three different RSA algorithms on three different processor architectures. A set of fixed values are used for p, q, M and e, and all the results are averaged over three measurements. Due to the low number values, all algorithms run both encryption and decryption 1000 times each to get a more accurate number. The montgomery algorithm is not run on the UDOO and the arduino, as the 32-bit limitation would require the numbers to be half the bit-size of the values used for the rest of the measurements. All numbers in the result are per 1000 encryptions and decryptions.



From Table~1 we can see that the binary method performs between 33 \% and 63 \% better than the recoding binary method. This can be explained by the nature of the algorithms. Unless the exponents contains large blocks of 1’s, the use of recoding will be of little value, and the overhead needed to calculate the inverse modulo will hurt the performance.

Another noticeable result, is that on the i7 processor, the binary method is approximately 4 times faster than the montgomery method, and the recoding binary method is approximately 2 times faster. This leads back to the problem discussed in the section about montgomery, where the amount of overhead overshadows the effects of faster exponentiation, and thus makes this algorithm slower, at least with small, conceptual numbers like in this experiment.

\section{Conclusion}
As can be seen from the results table, we did not get the same results as a mathematical simulation with a 2048-bit key would give. The main purpose of this project was to learn RSA on a deeper level, and to understand how such algorithms are implemented in software to make them sufficiently fast.  We have managed to implement four versions of the RSA modular exponentiation in C on three different processor platforms, and have understood how using the various algorithms impacts overall speed. The process has been both fun and educational.

\bibliographystyle{IEEEbib}
\bibliography{my}


\end{document}

